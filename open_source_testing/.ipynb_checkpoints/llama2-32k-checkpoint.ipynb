{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv(dotenv_path=Path(\"/scratch/yun.hy/llm-meta-analysis/.env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Flash Attention installed\n",
      ">>>> Flash RoPE installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# looks like need more than 1 gpu on frink to run this\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"togethercomputer/Llama-2-7B-32K-Instruct\",\n",
    "    trust_remote_code=True, torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"togethercomputer/Llama-2-7B-32K-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    result = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(result[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_type_prompt1(outcome: str):\n",
    "    return f'[INST]\\nIs the outcome of {outcome} from a randomized controlled trial a binary or continuous type? Output \"b\" if the outcome type is \"binary\", \"c\" if the outcome type is \"continuous\", and \"x\" if there is insufficient information to make any inference. Do not provide any explanation.\\n[\\INST]\\n\\n'\n",
    "\n",
    "def output_type_prompt2(abstract_and_results_xml: str, outcome: str):\n",
    "    return f'[INST]\\nArticle: {abstract_and_results_xml}. Based on the article, is the outcome of {outcome} from a randomized controlled trial a binary or continuous type? Output \"b\" if the outcome type is \"binary\", \"c\" if the outcome type is \"continuous\", and \"x\" if there is insufficient information to make any inference. Do not provide any explanation.\\n[\\INST]\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_outcomes_prompt(abstract_and_results_xml: str, intervention: str, comparator: str, outcome: str):\n",
    "    return f'''\n",
    "        [INST]\\nArticle: {abstract_and_results_xml}\n",
    "\n",
    "        Based on the given trial article, what is the 2x2 contingency table in YAML format for the following Intervention, Comparator, and Outcome? If any of the numerical information is unavailable or not extractable or not easy to calculate, please say \"x\". Only produce YAML response. Do not provide explanation.\n",
    "        The YAML format should include the fields \"events\" and \"group_size\" for only \"intervention\" and \"comparator\" but not \"outcome\". Example: \n",
    "        intervention:\n",
    "            events: NUMBER\n",
    "            group_size: NUMBER\t\n",
    "        comparator:\n",
    "            events: NUMBER\n",
    "            group_size: NUMBER\n",
    "\n",
    "        Intervention: {intervention}\n",
    "        Comparator: {comparator}\n",
    "        Outcome: {outcome}\\n[/INST]\\n\\n\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_outcomes_prompt(abstract_and_results_xml: str, intervention: str, comparator: str, outcome: str):\n",
    "    return f'''\n",
    "        [INST]\\nArticle: {abstract_and_results_xml}\n",
    "\n",
    "        Based on the given trial article, what is table of mean outcome and standard deviation in YAML format for the following Intervention, Comparator, and Outcome. Include the total size of each group for Intervention and Comparator. If any of the numerical information is unavailable or not extractable or not easy to calculate, please say \"x\". Only produce YAML response. Do not provide an explanation.\n",
    "        The YAML format should include the fields \"mean\", \"standard_deviation\", and \"group_size\" for only \"intervention\" and \"comparator\" but not \"outcome\". Example: \n",
    "        intervention:\n",
    "            mean: NUMBER\n",
    "            standard_deviation: NUMBER\n",
    "            group_size: NUMBER\n",
    "        comparator:\n",
    "            mean: NUMBER\n",
    "            standard_deviation: NUMBER\n",
    "            group_size: NUMBER\n",
    "\n",
    "        Intervention: {intervention}\n",
    "        Comparator: {comparator}\n",
    "        Outcome: {outcome}\\n[/INST]\\n\\n\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Outcome Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:395: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:400: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/tmp/tmp7da69a86/main.c: In function ‘list_to_cuuint64_array’:\n",
      "/tmp/tmp7da69a86/main.c:354:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "   for (Py_ssize_t i = 0; i < len; i++) {\n",
      "   ^\n",
      "/tmp/tmp7da69a86/main.c:354:3: note: use option -std=c99 or -std=gnu99 to compile your code\n",
      "/tmp/tmp7da69a86/main.c: In function ‘list_to_cuuint32_array’:\n",
      "/tmp/tmp7da69a86/main.c:365:3: error: ‘for’ loop initial declarations are only allowed in C99 mode\n",
      "   for (Py_ssize_t i = 0; i < len; i++) {\n",
      "   ^\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/bin/gcc', '/tmp/tmp7da69a86/main.c', '-O3', '-I/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/common/../third_party/cuda/include', '-I/home/yun.hy/.conda/envs/llm-meta-analysis/include/python3.11', '-I/tmp/tmp7da69a86', '-shared', '-fPIC', '-lcuda', '-o', '/tmp/tmp7da69a86/cuda_utils.cpython-311-x86_64-linux-gnu.so', '-L/lib64', '-L/lib', '-L/lib64', '-L/lib']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m output_type_prompt1(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmortality\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, tokenizer, prompt, max_new_tokens)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(model, tokenizer, prompt, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m      2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(result[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/generation/utils.py:1478\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1462\u001b[0m         input_ids,\n\u001b[1;32m   1463\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1475\u001b[0m     )\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1477\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/generation/utils.py:2315\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2312\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2315\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2318\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2319\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/frink/yun.hy/.cache/huggingface/modules/transformers_modules/togethercomputer/LLaMA-2-7B-32K/3c84db12268fac86081ec1229a5ef48414478c88/modeling_flash_llama.py:812\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, is_padded_inputs)\u001b[0m\n\u001b[1;32m    809\u001b[0m is_padded_inputs \u001b[38;5;241m=\u001b[39m ((attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m attention_mask\u001b[38;5;241m.\u001b[39mall()\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/frink/yun.hy/.cache/huggingface/modules/transformers_modules/togethercomputer/LLaMA-2-7B-32K/3c84db12268fac86081ec1229a5ef48414478c88/modeling_flash_llama.py:696\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, is_padded_inputs)\u001b[0m\n\u001b[1;32m    687\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    688\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    689\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m         is_padded_inputs\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 696\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/frink/yun.hy/.cache/huggingface/modules/transformers_modules/togethercomputer/LLaMA-2-7B-32K/3c84db12268fac86081ec1229a5ef48414478c88/modeling_flash_llama.py:447\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, is_padded_inputs, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    444\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/frink/yun.hy/.cache/huggingface/modules/transformers_modules/togethercomputer/LLaMA-2-7B-32K/3c84db12268fac86081ec1229a5ef48414478c88/modeling_flash_llama.py:347\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, is_padded_inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    345\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m--> 347\u001b[0m q, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m kv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([k, v], \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    350\u001b[0m kv \u001b[38;5;241m=\u001b[39m repeat_kv(kv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/work/frink/yun.hy/.cache/huggingface/modules/transformers_modules/togethercomputer/LLaMA-2-7B-32K/3c84db12268fac86081ec1229a5ef48414478c88/modeling_flash_llama.py:202\u001b[0m, in \u001b[0;36mFlashRotaryEmbedding.forward\u001b[0;34m(self, q, k, seqlen_offset)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_cos_sin_cache(q\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m seqlen_offset, device\u001b[38;5;241m=\u001b[39mq\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mq\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_rotary_emb_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cos_cached\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqlen_offset\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sin_cached\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseqlen_offset\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# inplace=True\u001b[39;49;00m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, apply_rotary_emb_func(\n\u001b[1;32m    206\u001b[0m         k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cos_cached[seqlen_offset:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sin_cached[seqlen_offset:],\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterleaved, \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# inplace=True\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/flash_attn/layers/rotary.py:122\u001b[0m, in \u001b[0;36mapply_rotary_emb\u001b[0;34m(x, cos, sin, interleaved, inplace, seqlen_offsets, cu_seqlens, max_seqlen)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_rotary_emb\u001b[39m(\n\u001b[1;32m     95\u001b[0m     x,\n\u001b[1;32m     96\u001b[0m     cos,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     max_seqlen: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m ):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m        x: (batch_size, seqlen, nheads, headdim) if cu_seqlens is None\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Apply rotary embedding to the first rotary_dim of x.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mApplyRotaryEmb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterleaved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseqlen_offsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seqlen\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/flash_attn/layers/rotary.py:48\u001b[0m, in \u001b[0;36mApplyRotaryEmb.forward\u001b[0;34m(ctx, x, cos, sin, interleaved, inplace, seqlen_offsets, cu_seqlens, max_seqlen)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     38\u001b[0m     ctx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     max_seqlen: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m ):\n\u001b[0;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseqlen_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterleaved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterleaved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seqlen_offsets, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     59\u001b[0m         ctx\u001b[38;5;241m.\u001b[39msave_for_backward(cos, sin, cu_seqlens)  \u001b[38;5;66;03m# Can't save int with save_for_backward\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/flash_attn/ops/triton/rotary.py:213\u001b[0m, in \u001b[0;36mapply_rotary\u001b[0;34m(x, cos, sin, seqlen_offsets, cu_seqlens, max_seqlen, interleaved, inplace, conjugate)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Need this, otherwise Triton tries to launch from cuda:0 and we get\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# ValueError: Pointer argument (at 0) cannot be accessed from Triton (cpu tensor?)\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m--> 213\u001b[0m     \u001b[43mrotary_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# data ptrs\u001b[39;49;00m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# shapes\u001b[39;49;00m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnheads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrotary_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen_ro\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# key for triton cache (limit number of compilations)\u001b[39;49;00m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_varlen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch_strides if not varlen else 0\u001b[39;49;00m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# seqlen_stride or total_seqlen_stride\u001b[39;49;00m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# nheads_stride\u001b[39;49;00m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# headdim_stride\u001b[39;49;00m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_varlen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# batch_strides if not varlen else 0\u001b[39;49;00m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# seqlen stride or total_seqlen_stride\u001b[39;49;00m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# nheads stride\u001b[39;49;00m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# headdim stride\u001b[39;49;00m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBLOCK_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseqlen_offsets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_varlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterleaved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconjugate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mBLOCK_M\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/jit.py:550\u001b[0m, in \u001b[0;36mJITFunction.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mbin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache[device][key]\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warmup:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;43mbin\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_wrapper\u001b[49m(\n\u001b[1;32m    551\u001b[0m         grid_0,\n\u001b[1;32m    552\u001b[0m         grid_1,\n\u001b[1;32m    553\u001b[0m         grid_2,\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mnum_warps,\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mnum_ctas,\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mclusterDims[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mclusterDims[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mclusterDims[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mshared,\n\u001b[1;32m    560\u001b[0m         stream,\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39mcu_function,\n\u001b[1;32m    562\u001b[0m         CompiledKernel\u001b[38;5;241m.\u001b[39mlaunch_enter_hook,\n\u001b[1;32m    563\u001b[0m         CompiledKernel\u001b[38;5;241m.\u001b[39mlaunch_exit_hook,\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28mbin\u001b[39m,\n\u001b[1;32m    565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mbin\u001b[39m\u001b[38;5;241m.\u001b[39massemble_tensormap_to_arg(non_constexpr_arg_values),\n\u001b[1;32m    566\u001b[0m     )\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbin\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/compiler/compiler.py:692\u001b[0m, in \u001b[0;36mCompiledKernel.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_wrapper\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 692\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/compiler/compiler.py:670\u001b[0m, in \u001b[0;36mCompiledKernel._init_handles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    669\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_current_device()\n\u001b[0;32m--> 670\u001b[0m     bin_path \u001b[38;5;241m=\u001b[39m {\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHIP\u001b[49m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhsaco_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, driver\u001b[38;5;241m.\u001b[39mCUDA: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcubin\u001b[39m\u001b[38;5;124m\"\u001b[39m}[driver\u001b[38;5;241m.\u001b[39mbackend]\n\u001b[1;32m    671\u001b[0m     max_shared \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_device_properties(device)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_shared_mem\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    672\u001b[0m     fn_load_binary \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_binary\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/driver.py:157\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj, name)\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/driver.py:154\u001b[0m, in \u001b[0;36mLazyProxy._initialize_obj\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/driver.py:187\u001b[0m, in \u001b[0;36minitialize_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HIPDriver()\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCudaDriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m UnsupportedDriver()\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/driver.py:77\u001b[0m, in \u001b[0;36mCudaDriver.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutils \u001b[38;5;241m=\u001b[39m \u001b[43mCudaUtils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCUDA\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/runtime/driver.py:47\u001b[0m, in \u001b[0;36mCudaUtils.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     46\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(src)\n\u001b[0;32m---> 47\u001b[0m so \u001b[38;5;241m=\u001b[39m \u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda_utils\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(so, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     49\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mput(f\u001b[38;5;241m.\u001b[39mread(), fname, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/common/build.py:106\u001b[0m, in \u001b[0;36m_build\u001b[0;34m(name, src, srcdir)\u001b[0m\n\u001b[1;32m    101\u001b[0m     cc_cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    102\u001b[0m         cc, src, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-O3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-I\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcu_include_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-I\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_include_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-I\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrcdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-shared\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-fPIC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-lcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-o\u001b[39m\u001b[38;5;124m\"\u001b[39m, so\n\u001b[1;32m    104\u001b[0m     ]\n\u001b[1;32m    105\u001b[0m     cc_cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-L\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdir\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cuda_lib_dirs]\n\u001b[0;32m--> 106\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m so\n",
      "File \u001b[0;32m~/.conda/envs/llm-meta-analysis/lib/python3.11/subprocess.py:413\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/bin/gcc', '/tmp/tmp7da69a86/main.c', '-O3', '-I/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/triton/common/../third_party/cuda/include', '-I/home/yun.hy/.conda/envs/llm-meta-analysis/include/python3.11', '-I/tmp/tmp7da69a86', '-shared', '-fPIC', '-lcuda', '-o', '/tmp/tmp7da69a86/cuda_utils.cpython-311-x86_64-linux-gnu.so', '-L/lib64', '-L/lib', '-L/lib64', '-L/lib']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "prompt = output_type_prompt1(\"mortality\")\n",
    "generate(model, tokenizer, prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Outcome Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "    <abstract><sec><title>OBJECTIVE</title><p>Moderate alcohol consumption is associated with reduced incidence of type 2 diabetes and cardiovascular mortality and increases adiponectin concentrations, but effects might differ according to sex and beverage consumed.</p></sec><sec><title>RESEARCH DESIGN AND METHODS</title><p>A total of 72 healthy individuals (22&#x02013;56 years) were enrolled in this randomized controlled crossover trial. After washout, two interventions for 3 weeks followed: ethanol (concentration 12.5%), beer (5.6%), or red wine (12.5%) equivalent to 30 g ethanol/day for men and 20 g/day for women or the same de-alcoholized beverages or water. Adiponectin was measured by sandwich enzyme-linked immunosorbent assay.</p></sec><sec><title>RESULTS</title><p>Among women, adiponectin significantly increased after consuming red wine (29.8%, <italic>P</italic> &#x0003c; 0.05) and increased among men after ethanol solution (17.4%, <italic>P</italic> &#x0003c; 0.05) and consuming beer (16.1%, <italic>P</italic> &#x0003c; 0.05). De-alcoholized beverages had no substantial effect on adiponectin concentrations.</p></sec><sec><title>CONCLUSIONS</title><p>Moderate amounts of ethanol-containing beverages increased adiponectin concentrations, but sex-specific effects might depend on type of beverage consumed.</p></sec></abstract><sec sec-type=\"results\"><title>RESULTS</title><p>Compliance was excellent according to self-report and counting of empty bottles returned. One participant was excluded because of protocol violation. Baseline characteristics including age, BMI, and liver enzymes did not differ within sexes and between intervention groups. Adiponectin concentrations were substantially higher among females (means 7.6&#x02013;8.8 &#x003bc;g/ml) than males (means 4.8&#x02013;6.3 &#x003bc;g/ml) but also did not differ between the intervention groups within each sex. Among females, adiponectin significantly increased after intervention with red wine (29.8%, <italic>P</italic> &#x0003c; 0.05) and increased among men after ethanol solution (17.4%, <italic>P</italic> &#x0003c; 0.05) and beer consumption (16.1%, <italic>P</italic> &#x0003c; 0.04). De-alcoholized beverages had no substantial effect on adiponectin concentrations (<xref ref-type=\"fig\" rid=\"F1\">Fig. 1</xref>).</p><fig id=\"F1\" position=\"float\"><label>Figure 1</label><caption><p>Mean percent change with standard deviation of adiponectin concentrations from baseline after intervention with beer (B+), de-alcoholized beer (B&#x02212;), red wine (RW+), de-alcoholized red wine (RW&#x02212;), enthanol solution (EtOH), and water (W) (*<italic>P</italic> &#x0003c; 0.05).</p></caption><graphic xlink:href=\"zdc0060975660001\" /></fig></sec>\n",
    "\"\"\"\n",
    "prompt = output_type_prompt2(article, \"Adiponectin in women\")\n",
    "generate(model, tokenizer, prompt, max_new_tokens=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Outcomes 2x2 Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "    <abstract><sec><title>Background:</title><p>Anderson-Hynes dismembered pyeloplasty is the gold standard therapeutic approach to ureteropelvic junction obstruction (UPJO). Use of a drainage method to protect the suture line from leakage is a matter of controversy.</p></sec><sec><title>Objectives:</title><p>We have compared the surgical outcome of Anderson-Hynes dismembered pyeloplasty for UPJO repair, with or without internal stenting.</p></sec><sec><title>Patients and Methods:</title><p>Eighty-two patients with UPJO were evaluated from 1996 to 2002. Complicated or emergent cases were excluded. Classic standard dismembered pyeloplasty was performed. Internal drainage, with a double j catheter, was performed in several patients, randomly. Another drain was also placed in the retroperitoneal space. The follow-up of patients was planned weekly, with patient visits and urine analysis and intravenous pyelography (IVP) and diethylene-triamine-pentaacetate (DTPA) scan after one month.</p></sec><sec><title>Results:</title><p>The study group consisted of 51 male and 31 female patients, who were mostly in the age range of 20 - 40 years. Comparing the two techniques of pyeloplasty with or without internal drainage, there was no significant difference between groups regarding extravasation and anastomosis complications, such as leakage, stenosis, urinoma formation or evidence of obstruction on postoperative IVP or DTPA scan. However, a higher incidence of catheter related urinary symptoms and flank pain was reported among those with internal stent.</p></sec><sec><title>Conclusions:</title><p>Pyeloplasty, with adequate spatulation, hemostasis and a watertight anastomosis, represents the mainstay of successful pyeloplasty and there may be no significant benefit for urethral stenting, especially in non-complicated cases.</p></sec></abstract><sec id=\"sec92058\"><title>4. Results</title><p>Double stenting was used in 30 cases and pyeloplasty without internal drainage was performed in 52 patients. Both groups were similar in age and sex distribution. The most common symptom was severe flank pain, which was present in 69% of patients. History of urinary tract infection was detected in 47% and 51% reported associated gastrointestinal symptoms. Pyuria was seen in 58% and only 36% of patients had positive urine culture, with <italic>Escherichia coli</italic> (<italic>E. coli</italic>) as the most common pathogen (60%). The preoperative sonographic evaluation and IVP results are shown in <xref ref-type=\"table\" rid=\"tbl23577\">Table 1</xref>. Intraoperative assessments showed ureteropelvic junction segmental atresia in 45 cases and aberrant vessels in 25 patients. The postoperative course was compared in two groups of patients, with and without internal drainage (<xref ref-type=\"table\" rid=\"tbl23578\">Table 2</xref>). Among patients with extravasation in DTPA scan in the stent free group, retrograde DJ stent was inserted in four cases that had unacceptable drainage due to inflammation. One patient had distal ureter obstruction because of distal ureter stone, that was treated by Trans-ureteral lithotripsy (TULP) and stent support. Three other cases had no anatomical abnormality, and they were followed and extravasation resolved spontaneously at control IVP after one month. Removal of DJ stent was planned in one month after operation. However, eight cases missed the time and late stent removal was accompanied with several complications, such as stone formation on the tip of catheter in the bladder of a patient that needed TULP before stent removal.</p><table-wrap id=\"tbl23577\" orientation=\"portrait\" position=\"float\"><label>Table 1.</label><caption><title> Results of Preoperative Ultrasonography and Intravenous Pyelography Evaluation <sup><xref ref-type=\"table-fn\" rid=\"fn21576\">a</xref>, <xref ref-type=\"table-fn\" rid=\"fn21577\">b</xref></sup></title></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th style=\"text-align: left;\" rowspan=\"1\" colspan=\"1\">Imaging Method</th><th rowspan=\"1\" colspan=\"1\">Right Kidney</th><th rowspan=\"1\" colspan=\"1\">Left Kidney</th></tr></thead><tbody><tr><td rowspan=\"1\" colspan=\"1\"><bold>Sonography</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Severe hydronephrosis</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">28 (34.6)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">35 (43.2)</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Moderate hydronephrosis</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">8 (9.9)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">9 (11.1)</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Mild hydronephrosis</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">6 (7.4)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">3 (3.7)</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Without hydronephrosis</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">39 (48)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">34 (42)</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>IVP</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">No secretion</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">6 (7.3)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">9 (11)</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Delayed secretion</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">33 (40.2)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">38 (46.3)</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Normal secretion</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">43 (52.4)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">35 (42.7)</td></tr></tbody></table><table-wrap-foot><fn id=\"fn21576\"><p><sup>a</sup>Abbreviation: IVP, intravenous pyelography</p></fn><fn id=\"fn21577\"><p><sup>b</sup>Data are presented as No. (%).</p></fn></table-wrap-foot></table-wrap><table-wrap id=\"tbl23578\" orientation=\"portrait\" position=\"float\"><label>Table 2.</label><caption><title> Comparing Postoperative Course Between Patients who Underwent Pyeloplasty With or Without Internal Drainage <sup><xref ref-type=\"table-fn\" rid=\"fn21578\">a</xref>, <xref ref-type=\"table-fn\" rid=\"fn21579\">b</xref></sup></title></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><th style=\"text-align: left;\" rowspan=\"1\" colspan=\"1\">Post-Operative Course</th><th rowspan=\"1\" colspan=\"1\">With Stent (n = 30)</th><th rowspan=\"1\" colspan=\"1\">Without Stent (n = 52)</th><th rowspan=\"1\" colspan=\"1\">P Value</th></tr></thead><tbody><tr><td rowspan=\"1\" colspan=\"1\"><bold>Drain removal</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">In 48 hours</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">12 (40)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">17 (32.7)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.583</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">After 2 days</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">18 (60)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">34 (65.4)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.632</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Mean hospital stay, d</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">36 &#x000b1; 1.74</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">3.4 &#x000b1; 1.30</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.841</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Urine analysis </bold><sup><bold /><bold><xref ref-type=\"table-fn\" rid=\"fn21580\">c</xref></bold></sup></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Hematuria</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">19/27</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">32/32</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.001</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Pyuria</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">12/27</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">20/32</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.008</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Post-operative IVP (one month later)</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Extravasation</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">2 (6.7)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">8 (15.3)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.209</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Delayed secretion</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">19 (63.3)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">25 (48.1)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.124</td></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Visible ureter</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">18 (60)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">41 (78.8)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.633</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>DTPA scan</bold><sup><bold /><bold><xref ref-type=\"table-fn\" rid=\"fn21581\">d</xref></bold></sup></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">Partial obstruction</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">8/20</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">13/44</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.716</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Urinary symptoms </bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">24 (80)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">2 (3.8)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.005</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Urinoma</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0 (0)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">1 (1.9)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.324</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Recurrence of stenosis</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\" /></tr><tr><td style=\"padding-left: 20pt;\" rowspan=\"1\" colspan=\"1\">reoperation</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0 (0)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">1 (1.9)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.324</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Stent remnants</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">2 (6.7)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0 (0)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.041</td></tr><tr><td rowspan=\"1\" colspan=\"1\"><bold>Flank pain at voiding</bold></td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">10 (33.3)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0 (0)</td><td style=\"text-align: center;\" rowspan=\"1\" colspan=\"1\">0.001</td></tr></tbody></table><table-wrap-foot><fn id=\"fn21578\"><p><sup>a</sup>Abbreviations: IVP, intravenous pyelography; DTPA, diethylene-triamine-pentaacetate.</p></fn><fn id=\"fn21579\"><p><sup>b</sup>Data are presented as No. (%).</p></fn><fn id=\"fn21580\"><p><sup>c</sup>Urine analysis was done in 27 patients of the stent group and 32 cases of the stent free group.</p></fn><fn id=\"fn21581\"><p><sup>d</sup>DTPA scan was done in 20 patients of stent group and 32 cases of stent free group.</p></fn></table-wrap-foot></table-wrap></sec>\n",
    "\"\"\"\n",
    "prompt = binary_outcomes_prompt(article, \"internal drainage group\", \"stentless cases\", \"ureteropelvic junction obstruction\")\n",
    "generate(model, tokenizer, prompt, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "    <abstract><p>In order to assess the effects of juice feedings during acute diarrhea a double-blind, randomized study was performed in 90 children, mean age of 10 &#x000b1; 4.28 months. Thirty patients with acute diarrhea were fed twice-daily 15 ml/kg of Apple Juice (AJ), 30 received White Grape Juice (WGJ), and 30 were given colored and flavored water (WA) as part of their age appropriate dietary intake. The duration and severity of diarrhea were the main endpoint variables of the study performed in a metabolic unit. The patients were similar among the 3 groups, had diarrhea for 50&#x02013;64 hours prior to admission, and were dehydrated when admitted to the unit for study. Half of the patients in each group were well nourished and the others had mild to moderate degrees of malnutrition. Rotavirus infection was the agent causing the illness in 63% of the patients. The infants fed juice ingested 14&#x02013;17% more calories than those given WA, (those receiving AJ and WGJ ingested 95 and 98 Calories/Kg/d respectively) whereas those receiving WA consumed 81 cal/kg/d). The increased energy intake was not at the expense of other foods or milk formula. The mean body weight gain was greater among patients receiving WGJ (+ 50.7 gm) as compared with the patients in the AJ group (+ 18.3 gm) or the patients fed WA (- 0.7 gm) (p = 0.08). The duration of the illness was longer in the infants fed juice as compared with those given WA (p = 0.006), the mean +/- SD duration in hours was 49.4 &#x000b1; 32.6, 47.5 &#x000b1; 38.9 and 26.5 &#x000b1; 27.4 in patients fed AJ, WGJ and WA respectively. All patients improved while ingesting juice and none of them developed persistent diarrhea; most recovered within 50 hours of the beginning of treatment and less than one fourth had diarrhea longer than 96 hours in the unit. The fecal losses were also increased among the juice fed patients (p = 0.001); the mean &#x000b1; SD fecal excretion in g/kg/h was 3.94 &#x000b1; 2.35, 3.59 &#x000b1; 2.35, and 2.19 &#x000b1; 1.63 in AJ, WGJ and WA respectively. The stool output was highest during the first day of treatment among all the patients, though those fed AJ had the highest volume of fecal losses and those who received WA had the lowest stool excretion. After the first day of treatment the differences in fecal excretion were not significant. The ability to tolerate carbohydrates during the illness and immediately after recovery was similar among the 3 groups of patients. Intake of juices with different fructose/glucose ratios and osmolarities resulted in more fecal losses and more prolonged diarrhea as compared with water feedings, but the patients given juice ingested more calories and gained more weight, particularly among those being fed the juice with equimolar concentrations of fructose and glucose.</p></abstract><sec><title>Results</title><p>The clinical characteristics and the laboratory data of the patients on admission are shown in tables <xref ref-type=\"table\" rid=\"T2\">2</xref> and <xref ref-type=\"table\" rid=\"T3\">3</xref>. The patients in each of the 3 groups were similar in age, duration and severity of diarrhea, presence of fever and vomiting. Also there were no differences in the proportion of patients who received breast feedings or in their nutritional status. Over 46% of patients studied in each group, were well nourished, more than 33% showed mild body weight deficits (&#x0003c;1 SD) and the others had mild to moderate malnutrition (&#x0003e;2 SD). All patients presented some dehydration (mild to moderate), and required no intravenous hydration therapy. Differences in clinical characteristics were not significant among groups.</p><table-wrap position=\"float\" id=\"T2\"><label>Table 2</label><caption><p>Clinical Characteristics of Patients on Admission</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><td></td><td align=\"left\" colspan=\"2\">Apple Juice n = 30</td><td align=\"center\" colspan=\"2\">White Grape Juice n = 30</td><td align=\"center\" colspan=\"2\">Water* n= 30</td></tr><tr><td></td><td colspan=\"6\"><hr></hr></td></tr><tr><td></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\">SD</td></tr></thead><tbody><tr><td align=\"left\">Age (months)</td><td align=\"left\">10.27</td><td align=\"center\">4.75</td><td align=\"center\">10.27</td><td align=\"center\">4.14</td><td align=\"center\">11.09</td><td align=\"center\">4.00</td></tr><tr><td align=\"left\">Diarrhea Duration (hr)</td><td align=\"left\">56.37</td><td align=\"center\">33.90</td><td align=\"center\">64.17</td><td align=\"center\">38.95</td><td align=\"center\">53.47</td><td align=\"center\">33.35</td></tr><tr><td align=\"left\">Fever Duration (hr)</td><td align=\"left\">37.77</td><td align=\"center\">33.46</td><td align=\"center\">47.11</td><td align=\"center\">49.62</td><td align=\"center\">41.04</td><td align=\"center\">38.11</td></tr><tr><td align=\"left\">Vomiting (h)</td><td align=\"left\">41.57</td><td align=\"center\">35.45</td><td align=\"center\">46.97</td><td align=\"center\">39.54</td><td align=\"center\">44.33</td><td align=\"center\">31.44</td></tr><tr><td align=\"left\">Breastfeeding</td><td align=\"left\">13 (n)</td><td align=\"center\">43.3%</td><td align=\"center\">16 (n)</td><td align=\"center\">53.3%</td><td align=\"center\">09 (n)</td><td align=\"center\">30.0 %</td></tr><tr><td align=\"left\">Well Nourished</td><td align=\"left\">16 (n)</td><td align=\"center\">53.3%</td><td align=\"center\">15 (n)</td><td align=\"center\">50.0%</td><td align=\"center\">14 (n)</td><td align=\"center\">46.6%</td></tr><tr><td align=\"left\">Nutritional Risk**</td><td align=\"left\">08(n)</td><td align=\"center\">26.6%</td><td align=\"center\">10(n)</td><td align=\"center\">33.3%</td><td align=\"center\">15(n)</td><td align=\"center\">50.0%</td></tr><tr><td align=\"left\">Mild Malnutrition</td><td align=\"left\">03 (n)</td><td align=\"center\">10.0%</td><td align=\"center\">05(n)</td><td align=\"center\">16.6%</td><td align=\"center\">01(n)</td><td align=\"center\">3.4%</td></tr><tr><td align=\"left\">Moderate/Severe Malnutrition</td><td align=\"left\">03(n)</td><td align=\"center\">10.0%</td><td align=\"center\">00(n)</td><td align=\"center\">0.0%</td><td align=\"center\">00(n)</td><td align=\"center\">0.0%</td></tr></tbody></table><table-wrap-foot><p>There were no statistically significant differences among groups, Analysis of Variance (ANOVA) p &#x0003e; 0.05. Fever was considered above 37.5 C temperature. Nutritional risk indicated body weight deficit &#x0003c; 1 SD, Mild malnutrition &#x0003c; 2 SD and Moderate/Severe Malnutrition &#x0003e; 2 SD.</p><p>n = number of patients and % of patients in each category.</p><p>*Colored/flavored to resemble juice</p></table-wrap-foot></table-wrap><table-wrap position=\"float\" id=\"T3\"><label>Table 3</label><caption><p>Laboratory Data of Patients on Admission*</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><td></td><td align=\"center\" colspan=\"2\">Apple Juice n = 30</td><td align=\"center\" colspan=\"2\">White Grape Juice n = 30</td><td align=\"center\" colspan=\"2\">Water<sup>*</sup> n = 30</td></tr><tr><td></td><td colspan=\"6\"><hr></hr></td></tr><tr><td></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td></tr></thead><tbody><tr><td align=\"left\">Serum Sodium (mEq/l)</td><td align=\"center\">142.03</td><td align=\"center\">5.45</td><td align=\"center\">140.96</td><td align=\"center\">3.51</td><td align=\"center\">140.51</td><td align=\"center\">5.39</td></tr><tr><td align=\"left\">Serum Potassium (mEq/l)</td><td align=\"center\">3.99</td><td align=\"center\">0.59</td><td align=\"center\">3.95</td><td align=\"center\">0.81</td><td align=\"center\">4.27</td><td align=\"center\">0.78</td></tr><tr><td align=\"left\">Hematocrit (%)</td><td align=\"center\">31.17</td><td align=\"center\">3.29</td><td align=\"center\">30.93</td><td align=\"center\">2.50</td><td align=\"center\">32.03</td><td align=\"center\">3.55</td></tr><tr><td align=\"left\">Hemoglobin (g/dl)</td><td align=\"center\">10.28</td><td align=\"center\">1.13</td><td align=\"center\">10.24</td><td align=\"center\">0.87</td><td align=\"center\">10.58</td><td align=\"center\">1.19</td></tr><tr><td align=\"left\">No Anemia</td><td align=\"center\">06(n)</td><td align=\"center\">20.0 %</td><td align=\"center\">02(n)</td><td align=\"center\">6.7 %</td><td align=\"center\">07(n)</td><td align=\"center\">23.3 %</td></tr><tr><td align=\"left\">Mild Anemia &#x02020;</td><td align=\"center\">20(n)</td><td align=\"center\">66.7 %</td><td align=\"center\">26(n)</td><td align=\"center\">86.6%</td><td align=\"center\">20(n)</td><td align=\"center\">66.7 %</td></tr><tr><td align=\"left\">Severe Anemia&#x02020;</td><td align=\"center\">04(n)</td><td align=\"center\">13.3 %</td><td align=\"center\">02(n)</td><td align=\"center\">6.7 %</td><td align=\"center\">03(n)</td><td align=\"center\">10.0 %</td></tr><tr><td colspan=\"7\"><hr></hr></td></tr><tr><td align=\"left\">Rotavirus</td><td align=\"center\">19(n)</td><td align=\"center\">63.3 %</td><td align=\"center\">18(n)</td><td align=\"center\">60.0 %</td><td align=\"center\">18(n)</td><td align=\"center\">60.0 %</td></tr><tr><td align=\"left\">Parasites&#x02021;</td><td align=\"center\">05(n)</td><td align=\"center\">16.7%.</td><td align=\"center\">04(n)</td><td align=\"center\">13.3 %</td><td align=\"center\">01(n)</td><td align=\"center\">3.3 %</td></tr></tbody></table><table-wrap-foot><p>*There were no significant differences among groups by ANOVA p &#x0003e; 0.05.</p><p>&#x02020; The criteria for mild Anemia was a hemoglobin less than 11.0 g/dl and for severe anemia was a hemoglobin less than 9 g/dl (WHO, 1989)</p><p>&#x02021; The parasites detected were: Ascaris lumbricoides (4), Giardia lamblia (1) Blastocytes hominis (1) Entamoeba coli (1) and Cryptosporidium parvum (3).</p><p>n = number of patients and % of patients in each category</p><p><sup>x</sup>Coloured/flavoured to resemble juice</p></table-wrap-foot></table-wrap><p>The serum electrolyte levels on admission to the hospital were similar among the 3 groups of patients (Table <xref ref-type=\"table\" rid=\"T3\">3</xref>). The hemoglobin (Hb) and hematocrit levels were also similar among groups, but two thirds of the patients exhibited mild degrees of anemia (Hb &#x0003c; 11 g), and in 9 infants there was a more severe degree (Hb &#x0003c; 9 g). In all instances iron supplementation was prescribed at the completion of the study. Rotavirus was identified in the stools of 55 of the patients, in 4 there was a pathogenic Escherichia Coli, in 10 there were parasites detected, and in the remaining 21 infants there were no stool pathogens identified.</p><p>The daily intake of the patients while in the study is shown in table <xref ref-type=\"table\" rid=\"T4\">4</xref>. The amount of water, milk formula, and breast milk feedings did not differ among the groups. However, the infants given WGJ readily consumed more juice than those fed AJ or WA. The total energy intake was higher in the juice fed groups as compared with the WA one. The WGJ patients ingested an average of 17% more calories on a daily basis, and the AJ infants consumed a mean of 14% more than the WA group. The increased energy intake was not at the expense of the other foods; both milk formula and complementary foods were ingested in similar quantities among the 3 groups of patients. The mean body weight gain was also higher among the juice fed patients; there was a mean weight gain of 18.3 gm in the AJ fed patients and of 50.6 gm in those given WGJ, whereas there was a mean loss of body weight (- 7.0 gm) among the WA group patients (p = 0.08).</p><table-wrap position=\"float\" id=\"T4\"><label>Table 4</label><caption><p>Daily intake of patients throughout the study (Kcal/Kg/day)</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><td></td><td align=\"center\" colspan=\"2\">Apple Juice n = 30</td><td align=\"center\" colspan=\"2\">White Grape Juice n = 30</td><td align=\"center\" colspan=\"2\">Water<sup>*</sup> n = 30</td><td align=\"center\">P value</td></tr><tr><td></td><td colspan=\"6\"><hr></hr></td><td></td></tr><tr><td></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td align=\"center\">&#x003c7;</td><td align=\"center\"><italic>SD</italic></td><td></td></tr></thead><tbody><tr><td align=\"left\">Total Calories</td><td align=\"center\">95.84</td><td align=\"center\">22.42</td><td align=\"center\">98.65</td><td align=\"center\">30.52</td><td align=\"center\">81.43</td><td align=\"center\">23.09</td><td align=\"center\">0.02*</td></tr><tr><td align=\"left\">Milk Formula</td><td align=\"center\">54.49</td><td align=\"center\">23.43</td><td align=\"center\">50.21</td><td align=\"center\">34.57</td><td align=\"center\">52.68</td><td align=\"center\">17.93</td><td align=\"center\">0.81</td></tr><tr><td align=\"left\">Breast Milk</td><td align=\"center\">08.71</td><td align=\"center\">11.57</td><td align=\"center\">15.80</td><td align=\"center\">18.56</td><td align=\"center\">05.45</td><td align=\"center\">10.96</td><td align=\"center\">0.06</td></tr><tr><td align=\"left\">Water</td><td align=\"center\">30.67</td><td align=\"center\">9.25</td><td align=\"center\">30.27</td><td align=\"center\">09.57</td><td align=\"center\">26.98</td><td align=\"center\">9.37</td><td align=\"center\">0.25</td></tr><tr><td align=\"left\">ORS</td><td align=\"center\">45.52</td><td align=\"center\">31.17</td><td align=\"center\">39.12</td><td align=\"center\">25.10</td><td align=\"center\">25.10</td><td align=\"center\">17.91</td><td align=\"center\">0.01**</td></tr><tr><td align=\"left\">\"Juices\"</td><td align=\"center\">18.61</td><td align=\"center\">3.93</td><td align=\"center\">20.98</td><td align=\"center\">5.35</td><td align=\"center\">17.32<sup>x</sup></td><td align=\"center\">4.37</td><td align=\"center\">0.01***</td></tr><tr><td align=\"left\">Total Liquids</td><td align=\"center\">157.90</td><td align=\"center\">38.26</td><td align=\"center\">158.42</td><td align=\"center\">50.35</td><td align=\"center\">127.70</td><td align=\"center\">28.25</td><td align=\"center\">0.001****</td></tr><tr><td align=\"left\">Complementary Foods</td><td align=\"center\">23.90</td><td align=\"center\">11.61</td><td align=\"center\">25.12</td><td align=\"center\">13.97</td><td align=\"center\">26.92</td><td align=\"center\">11.59</td><td align=\"center\">0.64</td></tr></tbody></table><table-wrap-foot><p>* Significant differences for Juice Groups vs Water, by ANOVA (Bonferroni)</p><p>** Significant differences for Water vs both juice groups</p><p>*** Significant differences for WGJ vs each other group</p><p>**** Significant Differences for Water vs each other group</p><p><sup>x </sup>Colored flavored water to resemble juice</p><p>Data are means +/- SD</p></table-wrap-foot></table-wrap><p>The duration of diarrhea differed among the 3 groups of patients (Table <xref ref-type=\"table\" rid=\"T5\">5</xref>). The total duration of diarrhea from the start of the illness through their recovery was decreased among the WA fed patients as compared with the AJ and WGJ: groups 111.7 &#x000b1; 48.2, 105.4 &#x000b1; 44.9 and 80.0 &#x000b1; 39.6 hours in AJ, WGJ and WA respectively. The differences in the duration of diarrhea were more marked while being treated in the hospital, the illness being shorter among patients given water instead of juice. However the majority of the patients recovered promptly regardless of the treatment given (Figure <xref ref-type=\"fig\" rid=\"F1\">1</xref>). Most of the patients improved within 50 hours after treatment was instituted, less than one forth of them had diarrhea persisting more than 96 hours and no one had it for more than 7 days.</p><table-wrap position=\"float\" id=\"T5\"><label>Table 5</label><caption><p>Duration of diarrhea in hours after randomization. Duration of diarrhea</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><td></td><td align=\"left\">Mean</td><td align=\"left\">SD</td></tr></thead><tbody><tr><td align=\"left\">Apple Juice</td><td align=\"left\">49.4</td><td align=\"left\">32.6</td></tr><tr><td align=\"left\">White Grape Juice</td><td align=\"left\">47.5</td><td align=\"left\">38.9</td></tr><tr><td align=\"left\">Water *</td><td align=\"left\">26.5</td><td align=\"left\">27.4</td></tr></tbody></table><table-wrap-foot><p>*Significant differences detect by Kruskal-Wallis p &#x0003c; 0.05. Water vs Juice groups. Data are hours +/- SD</p><p>Water coloured and flavored to resemble juice.</p></table-wrap-foot></table-wrap><fig position=\"float\" id=\"F1\"><label>Figure 1</label><caption><p>Survival analysis of total of diarrhea &#x02013; Kaplan-Meier, per group. * Statistic difference were found, p &#x0003c; 0,05, among water group and apple juice (P = 0,03) or white grape juice (P = 0,00).</p></caption><graphic xlink:href=\"1475-2891-4-23-1\"></graphic></fig><p>The severity of diarrhea also differed among the treatment groups (Table <xref ref-type=\"table\" rid=\"T6\">6</xref>). The stool output among the WA group of patients was significantly decreased as compared with those fed juice. During the first day of treatment those fed water had a mean stool output of 40% less than those fed juice. With improvement the differences among the treatments were minimized, and were no longer significant after the 2<sup>nd </sup>day of the illness. There were also significant differences in the severity of diarrhea among AJ and WGJ feedings (Table <xref ref-type=\"table\" rid=\"T6\">6</xref>). During the first 24 hours of treatment of the illness the patients receiving AJ had more marked stool losses than those fed WGJ. The mean excretion of stools was 21% higher in AJ fed patients than in the WGJ fed group.</p><table-wrap position=\"float\" id=\"T6\"><label>Table 6</label><caption><p>Fecal losses throughout the study and on the first day after randomization</p></caption><table frame=\"hsides\" rules=\"groups\"><thead><tr><td></td><td align=\"center\" colspan=\"2\"><bold>Total Losses (g/kg/hr)</bold></td><td align=\"center\" colspan=\"2\"><bold>First Day Losses g/kg/hr</bold></td></tr></thead><tbody><tr><td></td><td align=\"center\">Mean</td><td align=\"center\">SD</td><td align=\"center\">Mean</td><td align=\"center\">SD</td></tr><tr><td colspan=\"5\"><hr></hr></td></tr><tr><td align=\"left\">Apple Juice</td><td align=\"center\">3.94</td><td align=\"center\">2.35</td><td align=\"center\">4.13**</td><td align=\"center\">2.90</td></tr><tr><td align=\"left\">White Grape Juice</td><td align=\"center\">3.59</td><td align=\"center\">2.35</td><td align=\"center\">3.28**</td><td align=\"center\">2.39</td></tr><tr><td align=\"left\">Water<sup>x</sup></td><td align=\"center\">2.19*</td><td align=\"center\">1.63</td><td align=\"center\">1.78***</td><td align=\"center\">1.80</td></tr></tbody></table><table-wrap-foot><p>*Differences Among groups Water vs each of the juice groups (Kruskal-Wallis test) (p = 0.001)</p><p>** Differences between WGJ and AJ (p = 0.02)</p><p>*** Differences between Water and each of the juice groups (p = 0.001)</p><p><sup>x</sup>Coloured/flavoured to resemble juice</p></table-wrap-foot></table-wrap><p>The stool excretion data were treated for possible confounding and co-variables which could play a role in determining the final results. The covariance analysis and the robust regression showed a possible influence of ORS intake in the differences detected among the 3 groups of patients. The stool output was not different when the ORS intake was adjusted for the 3 groups of patients and the urinary outputs were also similar. Vomitus losses were not different among the 3 groups of patients, vomiting being present primarily during the first 24 hrs. of treatment.</p><p>There were 2 patients who had severe diarrhea during the treatment period (&#x0003e;10 ml/kg/hr). These patients were in the AJ group, one of these patients had acid stools and none had carbohydrates in feces. These 2 patients were treated with a lactose free formula, with improvement in stool output. There were three other patients who showed carbohydrate intolerance with acid stools or sugars in feces among the 3 groups, they improved without any dietary modifications.</p><p>Vomiting was present in all groups of patients: 22 (AJ), 26 (WGJ), and 19 (WA) during the first day of treatment; nevertheless this did not represented a limitation for Oral Rehydration Therapy (ORT) or feeding regimen and no patient was withdrawn or shifted to another therapy due to vomiting.</p><p>The response to juice feedings, as determined by breath hydrogen excretion after improvement of the illness, was not different among the 3 groups of patients. Most infants did not show breath hydrogen excretion levels above 20 ppm; and there were 17, 16 and 10 patients among the AJ, WGJ and WA groups respectively, who failed to show BH2 levels above 5 ppm at any time. Only 18 patients demonstrated a delta BH2 level increase above the basal value of more than 20 ppm. Eight of them were given AJ, 6 were fed WGJ and 4 received WA. There were 11, 16, and 13 patients in each group who exhibited a BH2 value above 20 ppm independent of the delta differences from basal among the WGJ, AJ and WA fed groups respectively. The differences in BH2 levels among groups were not significant.</p></sec>\n",
    "\"\"\"\n",
    "prompt = continuous_outcomes_prompt(article, \"White Grape Juice (WGJ)\", \"colored and flavored water (WA)\", \"The duration of the illness\")\n",
    "generate(model, tokenizer, prompt, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEXT STEPS:\n",
    "\n",
    "# 1. trying more examples from dev split (specifically articles with longer tokens)\n",
    "# 2. trying different prompts to get better results and also consistent format (e.g. json output format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
