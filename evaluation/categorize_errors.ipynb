{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c0d4081e357358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T06:59:46.851724Z",
     "start_time": "2024-04-07T06:59:46.848273Z"
    }
   },
   "outputs": [],
   "source": [
    "from evaluate_output import MetaAnalysisTaskEvaluator\n",
    "import utils\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423a6f3a134ac5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T06:59:46.870471Z",
     "start_time": "2024-04-07T06:59:46.856770Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorize_outcome_type(output_file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Categorizes the errors in the outcome type task\n",
    "    Categories:\n",
    "        1. Model outputs in an undesirable format\n",
    "        2. Model outputs binary when its continuous\n",
    "        3. Model outputs continuous when its binary\n",
    "        4. Model outputs unknown when the reference is known\n",
    "    \n",
    "    Args:\n",
    "        output_file_path: Output file path of the outcome type task\n",
    "    \n",
    "    Returns:\n",
    "        Dict: A dictionary containing the error categories and the record ids that fall into each category\n",
    "    \"\"\"\n",
    "    def is_badly_formatted_output(output: str) -> bool:\n",
    "        return output not in [\"A\", \"B\", \"C\"]\n",
    "    \n",
    "    evaluator = MetaAnalysisTaskEvaluator('outcome_type', output_file_path, 'metrics/outcome_type/', None)\n",
    "    evaluator.run_evaluation()\n",
    "    \n",
    "    errors = defaultdict(list)\n",
    "    # character_to_string_mapping = {\"A\": \"binary\", \"B\": \"continuous\", \"C\": \"x\"}\n",
    "    for record in evaluator.data:\n",
    "        \n",
    "        # Clean the output in the same way from `evaluate_output.py`\n",
    "        output = record['output'].replace(\"The answer is \", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\",\"\")\n",
    "        for char in output:\n",
    "            if not char.isspace():\n",
    "                output = char\n",
    "                break\n",
    "               \n",
    "        # Check for badly formatted outputs\n",
    "        if is_badly_formatted_output(output):\n",
    "            errors[\"badly_formatted_output\"].append(record['id'])\n",
    "            \n",
    "        # Check for unknown when reference is known\n",
    "        elif output == \"C\" and record['outcome_type'] != \"\":\n",
    "            errors[\"unknown_when_reference_known\"].append(record['id'])\n",
    "        \n",
    "        # Check for binary when continuous\n",
    "        elif output == \"B\" and record['outcome_type'] == \"binary\":\n",
    "            errors[\"binary_when_continuous\"].append(record['id'])\n",
    "            \n",
    "        # Check for continuous when binary\n",
    "        elif output == \"A\" and record['outcome_type'] == \"continuous\":\n",
    "            errors[\"continuous_when_binary\"].append(record['id'])\n",
    "            \n",
    "    return errors\n",
    "\n",
    "def categorize_outcomes(output_file_path: str, outcome_type: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Categorizes the errors in the binary outcomes task\n",
    "    Categories:\n",
    "        1. Model outputs in an undesirable format\n",
    "        2. Model has output but reference is unknown\n",
    "        3. Model outputs unknown but reference is known\n",
    "        4. Reference is and output is known but model outputs incorrect value\n",
    "        \n",
    "    Args:\n",
    "        output_file_path: Output file path of the given task\n",
    "        outcome_type: The outcome type of the task\n",
    "        \n",
    "    Returns:\n",
    "        Dict: A dictionary containing the error categories and the record ids that fall into each category\n",
    "    \"\"\"\n",
    "    evaluator = MetaAnalysisTaskEvaluator(outcome_type, output_file_path, 'metrics/' + outcome_type + '/', None)\n",
    "    evaluator.run_evaluation()\n",
    "\n",
    "    errors = defaultdict(list)\n",
    "    \n",
    "    # Define the reference keys and output keys based on the outcome type\n",
    "    if outcome_type == 'binary_outcomes':\n",
    "        reference_keys = [\"intervention_events\", \"intervention_group_size\", \"comparator_events\", \"comparator_group_size\"]\n",
    "        output_keys = [f'{category}_output' for category in reference_keys]\n",
    "    elif outcome_type == 'continuous_outcomes':\n",
    "        reference_keys = ['intervention_mean', 'intervention_standard_deviation', 'intervention_group_size', 'comparator_mean', 'comparator_standard_deviation', 'comparator_group_size']\n",
    "        output_keys = [f'{category}_output' for category in reference_keys]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid outcome type\")\n",
    "    \n",
    "    for record in evaluator.data:\n",
    "        # Check for badly formatted outputs\n",
    "        try:\n",
    "            _ = yaml.safe_load(utils.clean_yaml_output(record['output']))\n",
    "        except:\n",
    "            errors[\"badly_formatted_output\"].append(record['id'])\n",
    "            continue\n",
    "            \n",
    "        # Check for output but reference is unknown\n",
    "        for reference_key, output_key in zip(reference_keys, output_keys):\n",
    "            if record[reference_key] == \"x\" and record[output_key] != \"x\":\n",
    "                # Check if the record is already in the list\n",
    "                if record['id'] not in errors[\"known_output_but_reference_unknown\"]:\n",
    "                    errors[\"known_output_but_reference_unknown\"].append(record['id'])\n",
    "                \n",
    "            \n",
    "            # Check for unknown output but reference is known\n",
    "            if record[reference_key] != \"x\" and record[output_key] == \"x\":\n",
    "                # Check if the record is already in the list\n",
    "                if record['id'] not in errors[\"unknown_output_but_reference_known\"]:\n",
    "                    errors[\"unknown_output_but_reference_known\"].append(record['id'])\n",
    "                \n",
    "                \n",
    "            # Check for incorrect answer\n",
    "            if record[reference_key] != \"x\" and record[output_key] != \"x\":\n",
    "                if record[reference_key] != record[output_key]:\n",
    "                    # Check if the record is already in the list\n",
    "                    if record['id'] not in errors[\"incorrect_output\"]:\n",
    "                        errors[\"incorrect_output\"].append(record['id'])\n",
    "                        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ce44d9474d50b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T06:59:46.895251Z",
     "start_time": "2024-04-07T06:59:46.890910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the task:\n",
      "{\n",
      "    \"number_of_model_unknowns\": {\n",
      "        \"outcome_type\": 5,\n",
      "        \"total\": 5\n",
      "    },\n",
      "    \"number_of_reference_unknowns\": {\n",
      "        \"outcome_type\": 0,\n",
      "        \"total\": 0\n",
      "    },\n",
      "    \"exact_match_accuracy\": {\n",
      "        \"outcome_type\": 0.2896341463414634,\n",
      "        \"total\": 0.2896341463414634\n",
      "    },\n",
      "    \"partial_match_accuracy\": {\n",
      "        \"partial_match_accuracy_1\": 0.2896341463414634\n",
      "    },\n",
      "    \"outcome_type_f_score\": {\n",
      "        \"outcome_type\": {\n",
      "            \"f1_score_binary\": 0.4239401496259351,\n",
      "            \"f1_score_continuous\": 0.0792079207920792,\n",
      "            \"f1_score_unknown\": 0.0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "outcome_type_errors = categorize_outcome_type('outputs/outcome_type/olmo7B_outcome_type_test_output_20240326-12:06:30.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b611b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Type Errors:\n",
      "continuous_when_binary: 461\n",
      "unknown_when_reference_known: 5\n"
     ]
    }
   ],
   "source": [
    "# print(json.dumps(outcome_type_errors, indent=4))\n",
    "print(\"Outcome Type Errors:\")\n",
    "for key, value in outcome_type_errors.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3197bf13fea89e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T06:59:47.325371Z",
     "start_time": "2024-04-07T06:59:47.216392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 10\n",
      "    group_size: 397intervention:\n",
      "    events: 787\n",
      "    group_size: 392\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 3\n",
      "    group_size: 18intervention:\n",
      "    events: 10\n",
      "    group_size: 18\n",
      "comparator:\n",
      "    events: 6\n",
      "    group_size: 18\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 9\n",
      "    group_size: 399intervention:\n",
      "    events: 9\n",
      "    group_size: 389\n",
      "comparator:\n",
      "    events: 9\n",
      "    group_size: 398\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 74\n",
      "    group_size: 354intervention:\n",
      "    events: 354\n",
      "    group_size: 107\n",
      "comparator:\n",
      "    events: 178\n",
      "    group_size: 398\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 14\n",
      "    group_size: 56intervention:\n",
      "    events: 14\n",
      "    group_size: 56\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 8\n",
      "    group_size: 120\n",
      "comparator:\n",
      "    events: 120\n",
      "    group_size: 120intervention:\n",
      "    events: 8\n",
      "    group_size: 120\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 5\n",
      "    group_size: 16intervention:\n",
      "    events: 5\n",
      "    group_size: 16... chc a: n/a\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "    events: 71\n",
      "    group_size: 85\n",
      "comparator:\n",
      "    events: 84\n",
      "    group_size: 84intervention:\n",
      "    events: 7\n",
      "    group_size: 7\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "  events: 238\n",
      "  group_size: 371intervention:\n",
      "  events: 238\n",
      "  group_size: 371\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error in applying zero correction: Undefined results.\n",
      "Error parsing yaml string: intervention:\n",
      "  events: 2\n",
      "  group_size: 120\n",
      "comparator:\n",
      "  events: 2\n",
      "  group_size: 120intervention:\n",
      "  events: 108\n",
      "  group_size: 120\n",
      "Error in applying zero correction: Undefined results.\n",
      "Metrics for the task:\n",
      "{\n",
      "    \"number_of_model_unknowns\": {\n",
      "        \"intervention_events\": 72,\n",
      "        \"intervention_group_size\": 83,\n",
      "        \"comparator_events\": 77,\n",
      "        \"comparator_group_size\": 88,\n",
      "        \"total\": 320\n",
      "    },\n",
      "    \"number_of_reference_unknowns\": {\n",
      "        \"intervention_events\": 25,\n",
      "        \"intervention_group_size\": 3,\n",
      "        \"comparator_events\": 25,\n",
      "        \"comparator_group_size\": 3,\n",
      "        \"total\": 56\n",
      "    },\n",
      "    \"exact_match_accuracy\": {\n",
      "        \"intervention_events\": 0.08771929824561403,\n",
      "        \"intervention_group_size\": 0.14619883040935672,\n",
      "        \"comparator_events\": 0.13450292397660818,\n",
      "        \"comparator_group_size\": 0.1286549707602339,\n",
      "        \"total\": 0.0\n",
      "    },\n",
      "    \"partial_match_accuracy\": {\n",
      "        \"partial_match_accuracy_1\": 0.2807017543859649,\n",
      "        \"partial_match_accuracy_2\": 0.1871345029239766,\n",
      "        \"partial_match_accuracy_3\": 0.029239766081871343\n",
      "    },\n",
      "    \"percentage_of_computable_instances\": 0.17054263565891473,\n",
      "    \"point_estimates\": {\n",
      "        \"log_odds_ratio\": {\n",
      "            \"mean_absolute_error\": 1.066347774610942,\n",
      "            \"standard_error_of_mae\": 0.3305934049669066,\n",
      "            \"95_confidence_interval_of_mae\": [\n",
      "                0.41838470087580504,\n",
      "                1.714310848346079\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"num_of_chunked_instances\": 126\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "binary_errors = categorize_outcomes('outputs/binary_outcomes/olmo7B_binary_outcomes_test_output_20240403-18:44:49.json', 'binary_outcomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43378086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Outcome Errors:\n",
      "unknown_output_but_reference_known: 14\n",
      "badly_formatted_output: 115\n",
      "incorrect_output: 44\n",
      "known_output_but_reference_unknown: 5\n"
     ]
    }
   ],
   "source": [
    "# print(json.dumps(binary_errors, indent=4))\n",
    "print(\"Binary Outcome Errors:\")\n",
    "for key, value in binary_errors.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfba044e31ea0171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T06:59:48.781017Z",
     "start_time": "2024-04-07T06:59:48.406350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred for calculate standardized mean difference - intervention_mean: 0, control_mean: 0, intervention_sd: 0, control_sd: 0\n",
      "An exception occurred for calculate standardized mean difference - intervention_mean: 80).2, control_mean: 75).2, intervention_sd: 7.77, control_sd: 7.41\n",
      "Error parsing yaml string: intervention:\n",
      "     mean: 120.0\n",
      "     standard_deviation: 11.7\n",
      "     group_size: 60\n",
      "comparator:\n",
      "     mean: 88.4\n",
      "     standard_deviation: 11.8\n",
      "    group_size: 60\n",
      "Error parsing yaml string: intervention:\n",
      "     mean: 4.0\n",
      "     standard_deviation: 1.1\n",
      "     group_size: 28\n",
      "comparator:\n",
      "     mean: 11.5\n",
      "     standard_deviation: 3.3\n",
      "    group_size: 28\n",
      "Error parsing yaml string: intervention:\n",
      "    mean: 83\n",
      "    standard_deviation: 5\n",
      "    group_size: 10\n",
      "comparator:\n",
      "    mean: 74\n",
      "    standard_deviation: 5\n",
      "    group_size: 10intervention:\n",
      "    mean: 82\n",
      "    standard_deviation: 5\n",
      "    group_size: 10\n",
      "An exception occurred for calculate standardized mean difference - intervention_mean: 80).0, control_mean: 90).0, intervention_sd: 10.0, control_sd: 10.0\n",
      "An exception occurred for calculate standardized mean difference - intervention_mean: 83).0, control_mean: 74).0, intervention_sd: 5).0, control_sd: 5).0\n",
      "Error parsing yaml string: intervention:\n",
      "     mean: 123.7\n",
      "     standard_deviation: 11.6\n",
      "     group_size: 26\n",
      "comparator:\n",
      "     mean: 121.9\n",
      "     standard_deviation: 11.3\n",
      "    group_size: 27\n",
      "An exception occurred for calculate standardized mean difference - intervention_mean: 1, control_mean: 0, intervention_sd: 0, control_sd: 0\n",
      "Metrics for the task:\n",
      "{\n",
      "    \"number_of_model_unknowns\": {\n",
      "        \"intervention_mean\": 185,\n",
      "        \"intervention_standard_deviation\": 179,\n",
      "        \"intervention_group_size\": 264,\n",
      "        \"comparator_mean\": 188,\n",
      "        \"comparator_standard_deviation\": 179,\n",
      "        \"comparator_group_size\": 255,\n",
      "        \"total\": 1250\n",
      "    },\n",
      "    \"number_of_reference_unknowns\": {\n",
      "        \"intervention_mean\": 178,\n",
      "        \"intervention_standard_deviation\": 211,\n",
      "        \"intervention_group_size\": 40,\n",
      "        \"comparator_mean\": 178,\n",
      "        \"comparator_standard_deviation\": 212,\n",
      "        \"comparator_group_size\": 40,\n",
      "        \"total\": 859\n",
      "    },\n",
      "    \"exact_match_accuracy\": {\n",
      "        \"intervention_mean\": 0.21237113402061855,\n",
      "        \"intervention_standard_deviation\": 0.2907216494845361,\n",
      "        \"intervention_group_size\": 0.177319587628866,\n",
      "        \"comparator_mean\": 0.21030927835051547,\n",
      "        \"comparator_standard_deviation\": 0.26597938144329897,\n",
      "        \"comparator_group_size\": 0.1711340206185567,\n",
      "        \"total\": 0.03505154639175258\n",
      "    },\n",
      "    \"partial_match_accuracy\": {\n",
      "        \"partial_match_accuracy_1\": 0.49072164948453606,\n",
      "        \"partial_match_accuracy_2\": 0.38969072164948454,\n",
      "        \"partial_match_accuracy_3\": 0.21443298969072164,\n",
      "        \"partial_match_accuracy_4\": 0.15257731958762888,\n",
      "        \"partial_match_accuracy_5\": 0.04536082474226804\n",
      "    },\n",
      "    \"percentage_of_computable_instances\": 0.16483516483516483,\n",
      "    \"point_estimates\": {\n",
      "        \"standardized_mean_difference\": {\n",
      "            \"mean_absolute_error\": 2.042103536210533,\n",
      "            \"standard_error_of_mae\": 0.42240128196247456,\n",
      "            \"95_confidence_interval_of_mae\": [\n",
      "                1.2141970235640827,\n",
      "                2.870010048856983\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"num_of_chunked_instances\": 379\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "continuous_errors = categorize_outcomes('outputs/continuous_outcomes/olmo7B_continuous_outcomes_test_output_20240403-21:36:24.json', 'continuous_outcomes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec8f6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Outcome Errors:\n",
      "known_output_but_reference_unknown: 78\n",
      "badly_formatted_output: 229\n",
      "unknown_output_but_reference_known: 142\n",
      "incorrect_output: 123\n"
     ]
    }
   ],
   "source": [
    "# print(json.dumps(continuous_errors, indent=4))\n",
    "print(\"Continuous Outcome Errors:\")\n",
    "for key, value in continuous_errors.items():\n",
    "    print(f\"{key}: {len(value)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
