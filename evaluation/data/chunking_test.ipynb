{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b02a5a4cdbe170b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T00:36:50.980189Z",
     "start_time": "2024-03-22T00:36:50.966115Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from copy import deepcopy\n",
    "import tiktoken\n",
    "from pprint import pprint\n",
    "from IPython.display import clear_output\n",
    "from copy import copy\n",
    "\n",
    "XML_DIR = 'abstract_and_results_xml_files'\n",
    "DATASET_DIR = 'annotated_rct_dataset.json'\n",
    "\n",
    "with open(DATASET_DIR) as f:\n",
    "    meta_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec10eaf1143a6919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:09:31.372364Z",
     "start_time": "2024-03-21T22:09:31.366957Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_html_body(soup):\n",
    "    \"\"\"Given a BeautifulSoup object, remove the html and body tags\"\"\"\n",
    "    html_tag = soup.html\n",
    "    body_tag = soup.body\n",
    "    \n",
    "    # Unwrap the tags that are added by lxml\n",
    "    if html_tag is not None:\n",
    "        html_tag.unwrap()\n",
    "    if body_tag is not None:\n",
    "        body_tag.unwrap()\n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a672949eb0c07e0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:09:34.334187Z",
     "start_time": "2024-03-21T22:09:34.328453Z"
    }
   },
   "outputs": [],
   "source": [
    "# XML file directory\n",
    "def read_xml_directory(directory):\n",
    "    # BeautifulSoup objects for each XML file\n",
    "    soups = dict()\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            # Get the pmcid from the filename\n",
    "            pmcid = int(filename.split('.')[0].split('C')[1])\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                soup = BeautifulSoup(file.read(), 'lxml')\n",
    "                \n",
    "                remove_html_body(soup)\n",
    "                \n",
    "                soups[pmcid] = soup\n",
    "    \n",
    "    return soups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a67dd19de54c27ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:19:39.956460Z",
     "start_time": "2024-03-21T22:19:39.952121Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_abstract(soup):\n",
    "    \"\"\"Given a BeautifulSoup object, return the abstract text\"\"\"\n",
    "    abstract = soup.find('abstract')\n",
    "    if abstract:\n",
    "        return abstract\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def find_non_abstract(soup):\n",
    "    \"\"\"Given a BeautifulSoup object, return everything except the abstract\"\"\"\n",
    "    soup_str = str(soup)\n",
    "    new_soup = BeautifulSoup(soup_str, 'lxml')\n",
    "    \n",
    "    remove_html_body(new_soup)\n",
    "    \n",
    "    abstract = new_soup.find('abstract')\n",
    "    if abstract:\n",
    "        abstract.decompose()  # This will remove the tag from the new soup\n",
    "    return new_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "994bfc037ed8160e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T00:37:05.287976Z",
     "start_time": "2024-03-22T00:37:03.815834Z"
    }
   },
   "outputs": [],
   "source": [
    "soups = read_xml_directory(XML_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fde999925d09726c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:09:53.384849Z",
     "start_time": "2024-03-21T22:09:51.575816Z"
    }
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2ed894ff0e630dd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:33:34.197656Z",
     "start_time": "2024-03-21T22:33:34.194232Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    if ',' in str(value):\n",
    "        return int(value.replace(',', ''))\n",
    "    else:\n",
    "        return int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf95703278ac78e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T22:33:36.254197Z",
     "start_time": "2024-03-21T22:33:36.249313Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_meta_data(meta_data, pmcid):\n",
    "    \"\"\"Given the list of JSON objects, return a list of all record with the given pmcid\"\"\"\n",
    "    if type(pmcid) == list:\n",
    "        return [element for element in meta_data if convert_to_int(element['pmcid']) in pmcid]\n",
    "    elif type(pmcid) == int:\n",
    "        return [element for element in meta_data if convert_to_int(element['pmcid']) == int(pmcid)]\n",
    "    else:\n",
    "        raise ValueError('pmcid must be an integer or a list of integers')\n",
    "    \n",
    "# find_meta_data(meta_data, [2667135, 5498715])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6342117d78cb711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T23:49:23.196545Z",
     "start_time": "2024-03-21T23:49:23.193222Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_tokens(soup, encoding):\n",
    "    \"\"\"Given a soup object, return the number of tokens in the text\"\"\"\n",
    "    return len(encoding.encode(str(soup)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9c7c0d58e78826b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:08:09.445190Z",
     "start_time": "2024-03-22T01:08:09.442249Z"
    }
   },
   "outputs": [],
   "source": [
    "def condition():\n",
    "    \"\"\"Given a chunk of text, return True if the chunk meets the condition\"\"\"\n",
    "    \"\"\"\n",
    "    You are an expert on medical randomized controlled trials. You are trying to extract any relevant values for meta-analysis: intervention events, intervention group size, comparator events, comparator group size, intervention mean, intervention standard deviation, comparator mean, comparator standard deviation. Output only \"y\" if any of these values exists within the given chunk, output only \"n\" if the chunk contains none of these relevant values. Do not provide any explanation\n",
    "\n",
    "Intervention: Motivational interviewing through self-determination theory sessions\n",
    "Comparator: Standard education session\n",
    "Outcome: Scores of external regulation\n",
    "\n",
    "Chunk:\n",
    "    \"\"\"\n",
    "    return input('Is the model gonna return y or n (y/n) ') == 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aae5267e3dc82a6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T00:37:25.506559Z",
     "start_time": "2024-03-22T00:37:25.502401Z"
    }
   },
   "outputs": [],
   "source": [
    "def concatenate_soups(soup_list):\n",
    "    new_soup = BeautifulSoup(\"\", 'lxml')\n",
    "    for soup in soup_list:\n",
    "        new_soup.append(copy(soup))\n",
    "    return new_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "173aba4fd612f7ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:12:22.823700Z",
     "start_time": "2024-03-22T01:12:22.818154Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_xml(xml_element, min_tokens, condition):\n",
    "    \"\"\"\n",
    "    Chunk the XML element into smaller parts based on the specified condition and minimum number of tokens for a valid chunk.\n",
    "    \"\"\"\n",
    "    keep_chunks = []\n",
    "\n",
    "    def process_chunk(chunk):\n",
    "        \"\"\"\n",
    "        Process a chunk: If the condition is true and chunk length is greater than min_tokens, further chunk it recursively.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check if the condition is true for the chunk and chunk length is greater than min_tokens\n",
    "        pprint(chunk)\n",
    "        relevant = condition()\n",
    "        is_table = 'table' in chunk.name\n",
    "        clear_output()\n",
    "        \n",
    "        if is_table and relevant:\n",
    "            keep_chunks.append(chunk)\n",
    "        \n",
    "        elif count_tokens(chunk) >= min_tokens and relevant and not is_table:\n",
    "            # Chunk it further, recursively\n",
    "            keep_chunks.extend(chunk_xml(chunk, min_tokens, condition))\n",
    "    \n",
    "        # if the chunk is too small and the condition is true, keep it    \n",
    "        elif count_tokens(chunk) < min_tokens and relevant:\n",
    "            keep_chunks.append(chunk)\n",
    "            \n",
    "        # discard the chunk if the condition is false\n",
    "\n",
    "    # Iterate through the children of the XML element\n",
    "    for child in xml_element.children:\n",
    "        # Process the chunk\n",
    "        process_chunk(child)  \n",
    "    \n",
    "    # Return the list of chunks as a single soup object\n",
    "    return concatenate_soups(keep_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9e149bb14d6b2aa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T01:12:25.110586Z",
     "start_time": "2024-03-22T01:12:25.108137Z"
    }
   },
   "outputs": [],
   "source": [
    "test_soup = soups[5498715]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "68dd44714b13e56c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T00:37:40.046077Z",
     "start_time": "2024-03-22T00:37:37.541336Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks = chunk_xml(test_soup, 500, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9222021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6932"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(str(chunks)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
