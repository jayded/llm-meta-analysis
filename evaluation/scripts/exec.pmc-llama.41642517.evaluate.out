/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Arguments for the Clinical Trials Meta Analysis Task Runner:
Model:        pmc-llama
Task:         continuous_outcomes
Split:        test
Prompt Name:  yaml
Output Path:  /scratch/yun.hy/llm-meta-analysis/evaluation/outputs/continuous_outcomes
Is Test:      None

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:03<00:15,  3.20s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.90s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.78s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:11<00:05,  2.68s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.38s/it]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/485 [00:00<?, ?it/s] 44%|████▍     | 215/485 [00:00<00:00, 2147.79it/s] 89%|████████▊ | 430/485 [00:00<00:00, 2111.95it/s]100%|██████████| 485/485 [00:00<00:00, 2118.25it/s]
  0%|          | 0/485 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors
  0%|          | 1/485 [00:06<54:20,  6.74s/it]  0%|          | 2/485 [00:39<2:57:29, 22.05s/it]  1%|          | 3/485 [01:46<5:41:48, 42.55s/it]  1%|          | 4/485 [01:48<3:32:41, 26.53s/it]  1%|          | 5/485 [01:55<2:36:10, 19.52s/it]  1%|          | 6/485 [02:01<2:00:08, 15.05s/it]  1%|▏         | 7/485 [02:23<2:17:45, 17.29s/it]  2%|▏         | 8/485 [02:35<2:03:36, 15.55s/it]  2%|▏         | 9/485 [02:59<2:23:04, 18.03s/it]  2%|▏         | 10/485 [03:04<1:50:39, 13.98s/it]  2%|▏         | 11/485 [03:09<1:29:29, 11.33s/it]  2%|▏         | 12/485 [03:21<1:31:04, 11.55s/it]  3%|▎         | 13/485 [03:43<1:56:20, 14.79s/it]  3%|▎         | 14/485 [04:01<2:04:14, 15.83s/it]  3%|▎         | 15/485 [04:14<1:55:31, 14.75s/it]  3%|▎         | 16/485 [04:40<2:21:37, 18.12s/it]  4%|▎         | 17/485 [04:49<2:00:50, 15.49s/it]  4%|▎         | 18/485 [04:51<1:30:15, 11.60s/it]  4%|▍         | 19/485 [05:06<1:36:50, 12.47s/it]  4%|▍         | 20/485 [05:14<1:27:27, 11.29s/it]  4%|▍         | 21/485 [05:39<1:57:12, 15.16s/it]  5%|▍         | 22/485 [06:06<2:24:05, 18.67s/it]  5%|▍         | 23/485 [06:17<2:07:42, 16.59s/it]  5%|▍         | 24/485 [06:27<1:52:18, 14.62s/it]  5%|▌         | 25/485 [06:51<2:12:24, 17.27s/it]  5%|▌         | 26/485 [07:13<2:24:07, 18.84s/it]  6%|▌         | 27/485 [07:41<2:44:03, 21.49s/it]  6%|▌         | 28/485 [08:01<2:41:06, 21.15s/it]  6%|▌         | 29/485 [08:24<2:44:12, 21.61s/it]  6%|▌         | 30/485 [08:52<2:59:04, 23.61s/it]  6%|▋         | 31/485 [08:56<2:13:25, 17.63s/it]  7%|▋         | 32/485 [09:29<2:48:39, 22.34s/it]  7%|▋         | 33/485 [09:55<2:55:26, 23.29s/it]  7%|▋         | 34/485 [10:16<2:50:05, 22.63s/it]  7%|▋         | 35/485 [10:45<3:04:42, 24.63s/it]  7%|▋         | 36/485 [11:06<2:56:38, 23.61s/it]  8%|▊         | 37/485 [11:15<2:22:14, 19.05s/it]  8%|▊         | 38/485 [11:40<2:35:28, 20.87s/it]  8%|▊         | 39/485 [11:42<1:54:13, 15.37s/it]  8%|▊         | 40/485 [11:53<1:43:50, 14.00s/it]  8%|▊         | 41/485 [12:16<2:02:42, 16.58s/it]  9%|▊         | 42/485 [12:32<2:01:23, 16.44s/it]  9%|▉         | 43/485 [12:56<2:16:53, 18.58s/it]  9%|▉         | 44/485 [13:19<2:26:41, 19.96s/it]  9%|▉         | 45/485 [13:34<2:15:17, 18.45s/it]  9%|▉         | 46/485 [13:53<2:17:10, 18.75s/it]