/home/yun.hy/.conda/envs/llm-meta-analysis/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Arguments for the Clinical Trials Meta Analysis Task Runner:
Model:        pmc-llama
Task:         continuous_outcomes
Split:        test
Prompt Name:  yaml
Output Path:  /scratch/yun.hy/llm-meta-analysis/evaluation/outputs/continuous_outcomes
Is Test:      None

Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.34s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:09,  2.42s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.42s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:09<00:04,  2.38s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:11<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:12<00:00,  2.09s/it]
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
  0%|          | 0/485 [00:00<?, ?it/s] 45%|████▍     | 218/485 [00:00<00:00, 2173.91it/s] 91%|█████████ | 439/485 [00:00<00:00, 2189.46it/s]100%|██████████| 485/485 [00:00<00:00, 2187.22it/s]
  0%|          | 0/485 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
Token indices sequence length is longer than the specified maximum sequence length for this model (1780 > 512). Running this sequence through the model will result in indexing errors
  0%|          | 1/485 [00:08<1:10:26,  8.73s/it]  0%|          | 2/485 [00:41<3:03:17, 22.77s/it]  1%|          | 3/485 [01:35<4:57:58, 37.09s/it]  1%|          | 4/485 [01:38<3:09:58, 23.70s/it]  1%|          | 5/485 [01:47<2:27:35, 18.45s/it]  1%|          | 6/485 [01:53<1:51:37, 13.98s/it]  1%|▏         | 7/485 [02:15<2:12:40, 16.65s/it]  2%|▏         | 8/485 [02:24<1:54:22, 14.39s/it]  2%|▏         | 9/485 [02:50<2:22:27, 17.96s/it]  2%|▏         | 10/485 [02:54<1:47:10, 13.54s/it]  2%|▏         | 11/485 [02:56<1:20:03, 10.13s/it]  2%|▏         | 12/485 [03:08<1:23:02, 10.53s/it]  3%|▎         | 13/485 [03:28<1:45:57, 13.47s/it]  3%|▎         | 14/485 [03:42<1:46:27, 13.56s/it]  3%|▎         | 15/485 [03:54<1:42:44, 13.12s/it]  3%|▎         | 16/485 [04:23<2:19:44, 17.88s/it]  4%|▎         | 17/485 [04:30<1:55:39, 14.83s/it]  4%|▎         | 18/485 [04:36<1:34:45, 12.17s/it]  4%|▍         | 19/485 [04:53<1:44:59, 13.52s/it]  4%|▍         | 20/485 [04:58<1:25:49, 11.07s/it]  4%|▍         | 21/485 [05:19<1:46:44, 13.80s/it]  5%|▍         | 22/485 [05:44<2:14:35, 17.44s/it]  5%|▍         | 23/485 [05:53<1:54:29, 14.87s/it]  5%|▍         | 24/485 [05:58<1:30:32, 11.78s/it]  5%|▌         | 25/485 [06:20<1:52:57, 14.73s/it]  5%|▌         | 26/485 [06:52<2:32:23, 19.92s/it]  6%|▌         | 27/485 [07:06<2:19:38, 18.29s/it]  6%|▌         | 28/485 [07:25<2:20:47, 18.48s/it]  6%|▌         | 29/485 [07:46<2:25:59, 19.21s/it]  6%|▌         | 30/485 [08:09<2:33:28, 20.24s/it]  6%|▋         | 31/485 [08:14<1:59:54, 15.85s/it]  7%|▋         | 32/485 [08:50<2:45:45, 21.95s/it]  7%|▋         | 33/485 [09:16<2:54:35, 23.18s/it]  7%|▋         | 34/485 [09:38<2:51:13, 22.78s/it]  7%|▋         | 35/485 [10:14<3:19:11, 26.56s/it]  7%|▋         | 36/485 [10:42<3:22:35, 27.07s/it]  8%|▊         | 37/485 [10:53<2:46:42, 22.33s/it]  8%|▊         | 38/485 [11:15<2:45:32, 22.22s/it]  8%|▊         | 39/485 [11:18<2:01:14, 16.31s/it]  8%|▊         | 40/485 [11:27<1:44:55, 14.15s/it]  8%|▊         | 41/485 [11:48<1:59:51, 16.20s/it]  9%|▊         | 42/485 [11:59<1:48:01, 14.63s/it]  9%|▉         | 43/485 [12:28<2:20:04, 19.01s/it]  9%|▉         | 44/485 [12:50<2:26:26, 19.92s/it]  9%|▉         | 45/485 [13:05<2:14:49, 18.39s/it]  9%|▉         | 46/485 [13:28<2:25:34, 19.90s/it] 10%|▉         | 47/485 [14:01<2:54:24, 23.89s/it] 10%|▉         | 48/485 [14:13<2:28:14, 20.35s/it] 10%|█         | 49/485 [14:24<2:05:37, 17.29s/it] 10%|█         | 50/485 [14:45<2:14:32, 18.56s/it] 11%|█         | 51/485 [15:02<2:10:11, 18.00s/it] 11%|█         | 52/485 [15:27<2:26:16, 20.27s/it] 11%|█         | 53/485 [15:30<1:48:33, 15.08s/it]