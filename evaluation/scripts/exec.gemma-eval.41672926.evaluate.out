Arguments for the Clinical Trials Meta Analysis Task Evaluator:
Task:         binary_outcomes
Output Path:  /scratch/yun.hy/llm-meta-analysis/evaluation/outputs/binary_outcomes/gemma7B_binary_outcomes_test_output_20240403-13:36:04.json
Metrics Path: /scratch/yun.hy/llm-meta-analysis/evaluation/metrics/binary_outcomes/

Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
An exception occurred for calculate log odds ratio - intervention_events: 100%, control_events: 80%, intervention_total: 22, control_total: 20
Error in applying zero correction: Undefined results.
An exception occurred for calculate log odds ratio - intervention_events: 8/3, control_events: 8/3, intervention_total: 108, control_total: 24
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error parsing yaml string: ## 2x2 Contingency Table for Open Defecation - Adult Women

intervention:
  events: 83
  group_size: 1,525
comparator:
  events: 90
  group
Error parsing yaml string: Sure, here is the requested contingency table:

intervention:
  events: 55
  group_size: 39
comparator:
  events: 47
  group_size: 33

The text
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error parsing yaml string: Sure, here is the requested contingency table:

intervention:
  events: 26
  group_size: 39
comparator:
  events: 0
  group_size: 0

The text does not
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Error in applying zero correction: Undefined results.
Traceback (most recent call last):
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 259, in <module>
    task_evaluator.run_evaluation()
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 215, in run_evaluation
    self.__preprocess_binary_outcomes_results()
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 100, in __preprocess_binary_outcomes_results
    output_dict = aggregate_yaml_output_for_binary_outcomes(yaml_dict_list)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/utils.py", line 179, in aggregate_yaml_output_for_binary_outcomes
    for key in yaml_dict.keys():
               ^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'keys'
Arguments for the Clinical Trials Meta Analysis Task Evaluator:
Task:         continuous_outcomes
Output Path:  /scratch/yun.hy/llm-meta-analysis/evaluation/outputs/continuous_outcomes/gemma7B_continuous_outcomes_test_output_20240403-14:40:46.json
Metrics Path: /scratch/yun.hy/llm-meta-analysis/evaluation/metrics/continuous_outcomes

Traceback (most recent call last):
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 259, in <module>
    task_evaluator.run_evaluation()
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 217, in run_evaluation
    self.__preprocess_continuous_outcomes_results()
  File "/scratch/yun.hy/llm-meta-analysis/evaluation/scripts/../evaluate_output.py", line 179, in __preprocess_continuous_outcomes_results
    im_output = intervention["mean"] if "mean" in intervention else "x"
                                        ^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'NoneType' is not iterable
